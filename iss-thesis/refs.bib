% =====================================================================
% Diffusion Models - Foundational
% =====================================================================

@inproceedings{ho2020denoising,
  author    = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  title     = {Denoising Diffusion Probabilistic Models},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {33},
  pages     = {6840--6851},
  year      = {2020}
}

@inproceedings{song2021scorebased,
  author    = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  title     = {Score-Based Generative Modeling through Stochastic Differential Equations},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021}
}

@inproceedings{sohldickstein2015deep,
  author    = {Sohl-Dickstein, Jascha and Weiss, Eric A. and Maheswaranathan, Niru and Ganguli, Surya},
  title     = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {2256--2265},
  year      = {2015}
}

@inproceedings{nichol2021improved,
  author    = {Nichol, Alexander Quinn and Dhariwal, Prafulla},
  title     = {Improved Denoising Diffusion Probabilistic Models},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {8162--8171},
  year      = {2021}
}

@inproceedings{dhariwal2021diffusion,
  author    = {Dhariwal, Prafulla and Nichol, Alexander},
  title     = {Diffusion Models Beat {GANs} on Image Synthesis},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {34},
  pages     = {8780--8794},
  year      = {2021}
}

% =====================================================================
% Latent Diffusion Models
% =====================================================================

@inproceedings{rombach2022highresolution,
  author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  title     = {High-Resolution Image Synthesis with Latent Diffusion Models},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {10684--10695},
  year      = {2022}
}

@inproceedings{karras2022elucidating,
  author    = {Karras, Timo and Aittala, Miika and Aila, Timo and Laine, Samuli},
  title     = {Elucidating the Design Space of Diffusion-Based Generative Models},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {35},
  pages     = {26565--26577},
  year      = {2022}
}

% =====================================================================
% Video Diffusion Models
% =====================================================================

@article{blattmann2023stable,
  author  = {Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and Jampani, Varun and Rombach, Robin},
  title   = {Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets},
  journal = {arXiv preprint arXiv:2311.15127},
  year    = {2023}
}

@article{ho2022video,
  author  = {Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J.},
  title   = {Video Diffusion Models},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume  = {35},
  pages   = {8633--8646},
  year    = {2022}
}

@article{singer2023makeavideo,
  author  = {Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and Parikh, Devi and Gupta, Sonal and Taigman, Yaniv},
  title   = {Make-A-Video: Text-to-Video Generation without Text-Video Data},
  journal = {arXiv preprint arXiv:2209.14792},
  year    = {2023}
}

@article{blattmann2023align,
  author  = {Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  title   = {Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models},
  journal = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages   = {22563--22575},
  year    = {2023}
}

@article{guo2024animatediff,
  author  = {Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  title   = {AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2024}
}

% =====================================================================
% Variational Autoencoders
% =====================================================================

@article{kingma2014autoencoding,
  author  = {Kingma, Diederik P. and Welling, Max},
  title   = {Auto-Encoding Variational {Bayes}},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2014}
}

@inproceedings{rezende2014stochastic,
  author    = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  title     = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {1278--1286},
  year      = {2014}
}

@article{vahdat2020nvae,
  author  = {Vahdat, Arash and Kautz, Jan},
  title   = {{NVAE}: A Deep Hierarchical Variational Autoencoder},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume  = {33},
  pages   = {19667--19679},
  year    = {2020}
}

@article{esser2021taming,
  author  = {Esser, Patrick and Rombach, Robin and Ommer, Bj{\"o}rn},
  title   = {Taming Transformers for High-Resolution Image Synthesis},
  journal = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages   = {12873--12883},
  year    = {2021}
}

% =====================================================================
% Controllable Generation / ControlNet
% =====================================================================

@article{zhang2023adding,
  author  = {Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  title   = {Adding Conditional Control to Text-to-Image Diffusion Models},
  journal = {IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages   = {3836--3847},
  year    = {2023}
}

@article{luo2025ctrlv,
  author  = {Luo, Ge Ya and Luo, ZhiHao and Gosselin, Anthony and Jolicoeur-Martineau, Alexia and Pal, Christopher},
  title   = {Ctrl-V: Higher Fidelity Autonomous Vehicle Video Generation with Bounding-Box Controlled Object Motion},
  journal = {Transactions on Machine Learning Research (TMLR)},
  year    = {2025}
}

@article{wang2024boximator,
  author  = {Wang, Jiawei and Jiang, Yuchen and Zhong, Wentao and Yang, Zhe and Miao, Chunping and Li, Jiashuo and Chai, Yuchao and Song, Ruibing and Liu, Hao and Zhou, Aimin and others},
  title   = {Boximator: Generating Rich and Controllable Motions for Video Synthesis},
  journal = {arXiv preprint arXiv:2402.01566},
  year    = {2024}
}

@article{hu2023videocontrolnet,
  author  = {Hu, Zhihao and Xu, Dong},
  title   = {VideoControlNet: A Motion-Guided Video-to-Video Translation Framework by Using Diffusion Model with ControlNet},
  journal = {arXiv preprint arXiv:2307.14073},
  year    = {2023}
}

@article{chen2023controlavideo,
  author  = {Chen, Weifeng and Wu, Jie and Xie, Pan and Wu, Hefeng and Li, Jiashi and Xia, Xin and Xiao, Xuefeng and Lin, Liang},
  title   = {Control-A-Video: Controllable Text-to-Video Generation with Diffusion Models},
  journal = {arXiv preprint arXiv:2305.13840},
  year    = {2023}
}

@article{mou2024revideo,
  author  = {Mou, Chong and Cao, Mingdeng and Wang, Xintao and Zhang, Zhaoyang and Shan, Ying and Zhang, Jian},
  title   = {ReVideo: Remake a Video with Motion and Content Control},
  journal = {arXiv preprint arXiv:2405.13865},
  year    = {2024}
}

% =====================================================================
% Autonomous Driving Video Generation / Synthetic Data
% =====================================================================

@article{yang2024generalized,
  author  = {Yang, Zhuoling and Li, Zhaoyang and Shao, Jingyu and Liu, Ziwei and Liu, Yu},
  title   = {Generalized Predictive Model for Autonomous Driving},
  journal = {arXiv preprint arXiv:2403.09630},
  year    = {2024}
}

@article{gao2024vista,
  author  = {Gao, Shenyuan and Geng, Jiazhi and Li, Zhenhua and Li, Rui and Xu, Hang and Li, Hongsheng},
  title   = {{VISTA}: A Generalizable Driving World Model with High Fidelity and Versatile Controllability},
  journal = {arXiv preprint arXiv:2405.17398},
  year    = {2024}
}

@article{li2023drivingdiffusion,
  author  = {Li, Xiaofan and Zhang, Yifu and Ye, Xiaoqing},
  title   = {DrivingDiffusion: Layout-Guided Multi-View Driving Scene Video Generation with Latent Diffusion Model},
  journal = {arXiv preprint arXiv:2310.07771},
  year    = {2023}
}

@article{swerdlow2024svsgan,
  author  = {Swerdlow, Alexander and Xu, Runsheng and Zhou, Bolei},
  title   = {Street View Synthesis with Gaussian Splatting and Diffusion Prior},
  journal = {arXiv preprint arXiv:2403.09637},
  year    = {2024}
}

% =====================================================================
% Semantic Segmentation
% =====================================================================

@article{long2015fully,
  author  = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  title   = {Fully Convolutional Networks for Semantic Segmentation},
  journal = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages   = {3431--3440},
  year    = {2015}
}

@article{chen2018encoderdecoder,
  author  = {Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartmut},
  title   = {Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation},
  journal = {European Conference on Computer Vision (ECCV)},
  pages   = {801--818},
  year    = {2018}
}

% =====================================================================
% Datasets
% =====================================================================

@inproceedings{liao2022kitti360,
  author    = {Liao, Yiyi and Xie, Jun and Geiger, Andreas},
  title     = {{KITTI}-360: A Novel Dataset and Benchmarks for Urban Scene Understanding in 2D and 3D},
  booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume    = {45},
  number    = {3},
  pages     = {3292--3310},
  year      = {2022}
}

@inproceedings{geiger2012are,
  author    = {Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  title     = {Are We Ready for Autonomous Driving? {The KITTI} Vision Benchmark Suite},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {3354--3361},
  year      = {2012}
}

@article{cordts2016cityscapes,
  author  = {Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  title   = {The Cityscapes Dataset for Semantic Urban Scene Understanding},
  journal = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages   = {3213--3223},
  year    = {2016}
}

% =====================================================================
% Evaluation Metrics
% =====================================================================

@article{unterthiner2019fvd,
  author  = {Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  title   = {Towards Accurate Generative Models of Video: A New Metric and Challenges},
  journal = {arXiv preprint arXiv:1812.01717},
  year    = {2019}
}

@inproceedings{heusel2017gans,
  author    = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  title     = {{GANs} Trained by a Two Time-Scale Update Rule Converge to a Local {Nash} Equilibrium},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {30},
  pages     = {6626--6637},
  year      = {2017}
}

% =====================================================================
% UNet Architecture
% =====================================================================

@inproceedings{ronneberger2015unet,
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  title     = {{U-Net}: Convolutional Networks for Biomedical Image Segmentation},
  booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  pages     = {234--241},
  year      = {2015}
}

% =====================================================================
% Attention and Transformers
% =====================================================================

@inproceedings{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  title     = {Attention is All You Need},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {30},
  pages     = {5998--6008},
  year      = {2017}
}

@inproceedings{dosovitskiy2021image,
  author    = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021}
}

% =====================================================================
% CLIP
% =====================================================================

@inproceedings{radford2021learning,
  author    = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages     = {8748--8763},
  year      = {2021}
}

% =====================================================================
% Loss Functions
% =====================================================================

@inproceedings{milletari2016vnet,
  author    = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
  title     = {{V-Net}: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation},
  booktitle = {International Conference on 3D Vision (3DV)},
  pages     = {565--571},
  year      = {2016}
}

@article{berman2018lovasz,
  author  = {Berman, Maxim and Triki, Amal Rannen and Blaschko, Matthew B.},
  title   = {The {Lov\'asz-Softmax} Loss: A Tractable Surrogate for the Optimization of the Intersection-Over-Union Measure in Neural Networks},
  journal = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages   = {4413--4421},
  year    = {2018}
}

% =====================================================================
% GANs for Comparison
% =====================================================================

@article{goodfellow2014generative,
  author  = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  title   = {Generative Adversarial Nets},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume  = {27},
  pages   = {2672--2680},
  year    = {2014}
}

% =====================================================================
% Classifier-Free Guidance
% =====================================================================

@article{ho2022classifierfree,
  author  = {Ho, Jonathan and Salimans, Tim},
  title   = {Classifier-Free Diffusion Guidance},
  journal = {arXiv preprint arXiv:2207.12598},
  year    = {2022}
}

% =====================================================================
% Perceptual Losses
% =====================================================================

@inproceedings{zhang2018unreasonable,
  author    = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
  title     = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {586--595},
  year      = {2018}
}

% =====================================================================
% Misc / Optimization
% =====================================================================

@article{loshchilov2019decoupled,
  author  = {Loshchilov, Ilya and Hutter, Frank},
  title   = {Decoupled Weight Decay Regularization},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2019}
}

@article{kingma2015adam,
  author  = {Kingma, Diederik P. and Ba, Jimmy},
  title   = {Adam: A Method for Stochastic Optimization},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2015}
}

% =====================================================================
% Image-to-Image Translation
% =====================================================================

@inproceedings{isola2017image,
  author    = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
  title     = {Image-to-Image Translation with Conditional Adversarial Networks},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {1125--1134},
  year      = {2017}
}

@inproceedings{park2019semantic,
  author    = {Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and Zhu, Jun-Yan},
  title     = {Semantic Image Synthesis with Spatially-Adaptive Normalization},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {2337--2346},
  year      = {2019}
}

% =====================================================================
% Inception Network (for FID)
% =====================================================================

@inproceedings{szegedy2016rethinking,
  author    = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  title     = {Rethinking the Inception Architecture for Computer Vision},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {2818--2826},
  year      = {2016}
}

% =====================================================================
% Batch / Group Normalization
% =====================================================================

@inproceedings{wu2018group,
  author    = {Wu, Yuxin and He, Kaiming},
  title     = {Group Normalization},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages     = {3--19},
  year      = {2018}
}

% =====================================================================
% I3D for FVD
% =====================================================================

@inproceedings{carreira2017quo,
  author    = {Carreira, Jo{\~a}o and Zisserman, Andrew},
  title     = {Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {6299--6308},
  year      = {2017}
}

% =====================================================================
% Hugging Face Diffusers
% =====================================================================

@article{von-platen-etal-2022-diffusers,
  author  = {von Platen, Patrick and Patil, Suraj and Lozhkov, Anton and Cuenca, Pedro and Lambert, Nathan and Rasul, Kashif and Davaadorj, Mishig and Wolf, Thomas},
  title   = {Diffusers: State-of-the-art diffusion models},
  journal = {GitHub repository},
  year    = {2022},
  howpublished = {\url{https://github.com/huggingface/diffusers}}
}

% =====================================================================
% World Models / Driving Simulation
% =====================================================================

@article{hu2023gaia,
  author  = {Hu, Anthony and Russell, Lloyd and Yeo, Hudson and Murez, Zak and Fedoseev, George and Kendall, Alex and Shotton, Jamie and Corber, Gianluca},
  title   = {{GAIA}-1: A Generative World Model for Autonomous Driving},
  journal = {arXiv preprint arXiv:2309.17080},
  year    = {2023}
}

@article{wang2024driving,
  author  = {Wang, Yuqi and He, Jiawei and Fan, Lue and Li, Hongxin and Chen, Yuntao and Zhang, Zhaoxiang},
  title   = {Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving},
  journal = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages   = {14749--14759},
  year    = {2024}
}

